---
output: html_document
editor_options: 
  chunk_output_type: inline
---

# Data Management

[[Chunk Version]](_book/files/08-data_management-chunks.Rmd)

## Defining Data

### What is Data? {.unnumbered}

In research, data refers to information collected to answer questions, test hypotheses, or explore patterns. Data can take many forms---numbers, text, images---and understanding these forms is essential for effective analysis. In RStudio, data is organized in tables (data frames), where rows represent individual observations, and columns represent variables.

### What is Data in Mass Communication Research? {.unnumbered}

In mass communication research, data can come from various sources, including audience metrics, media content, or public opinion surveys. For example, the **IMDb_Economist_tv_ratings.csv** dataset contains information about TV shows, such as titles, seasons, average ratings, audience share, and genres. These data points can be used to analyze audience preferences, media reception, or trends across different types of programming.

### Qualitative vs. Quantitative Data {.unnumbered}

In mass communication research, data can be classified as either qualitative or quantitative.

-   **Qualitative Data**: Qualitative data are non-numerical and often textual or categorical. In the **IMDb_Economist_tv_ratings.csv** dataset, variables such as `title` and `genres` are qualitative. These data provide descriptive details, helping researchers interpret cultural themes or trends in media content. For example, the `genres` variable includes values like "Drama," "Mystery," and "Sci-Fi," which categorize each show based on its narrative content.

-   **Quantitative Data**: Quantitative data are numerical and can be measured or counted. These data are used to perform statistical analyses. In the **IMDb_Economist_tv_ratings.csv** dataset, variables such as `av_rating` (average rating) and `share` (audience share) are quantitative. These values allow researchers to explore trends and relationships using statistical methods, such as analyzing how audience ratings vary by genre or season.

## Variables and Observations

In RStudio, datasets are organized in a tabular format, where **columns represent variables** and **rows represent observations**.

-   **Variables**: Variables represent the characteristics or attributes being measured. In the **IMDb_Economist_tv_ratings.csv** dataset, variables include `title`, `seasonNumber`, `av_rating`, `share`, and `genres`. Each variable holds a specific type of information. For example, the `av_rating` variable represents the average IMDb rating for each TV show, while `genres` lists the categories of the show.

-   **Observations**: Observations are individual data points in the dataset. In this dataset, each row represents a unique combination of a TV show and its season. For example, one observation might represent Season 1 of "12 Monkeys," with its corresponding `av_rating` and `share`. These rows are the building blocks for data analysis, as they provide the raw material that is examined and processed.

### Explanation of Data Types {.unnumbered}

Different types of data are used in mass communication research, each requiring different methods of analysis. Here's how the data types in the **IMDb_Economist_tv_ratings.csv** dataset break down:

-   **Nominal Data**: Nominal data are qualitative and label variables without any inherent order. The `title` variable is an example of nominal data, as it categorizes the different TV shows without implying any ranking or hierarchy.

-   **Ordinal Data**: Ordinal data are categorical but have a defined order. While there are no ordinal variables in this specific dataset, an example might be a variable representing user rankings (e.g., "Poor," "Average," "Good").

-   **Discrete Data**: Discrete data represent ordered values where the differences between values are meaningful, but there is no true zero point. In this dataset, `av_rating` could be considered interval data, as it represents IMDb ratings on a scale where the differences between values are consistent, but there is no absolute zero.

-   **Continuous Data**: Continuous data can take any value within a given range. The `share` variable (audience share) is an example of continuous data because it represents the percentage of the total audience, which can vary across a continuous spectrum.

-   **Dichotomous or Binary Data**: Dichotomous data have only two possible values, such as "yes/no" or "true/false." Although this dataset does not contain any binary variables, a typical example might be whether a show was renewed for another season (Yes/No).

## Inputting Data

In RStudio, entering and importing data are essential tasks for conducting research. This section introduces DataEditR for manual data input and covers methods for importing data from external files like CSVs. The **IMDb_Economist_tv_ratings.csv** dataset is used in the examples below, which contains information about TV shows, including titles, seasons, ratings, and genres.

### Data Structures in R {.unnumbered}

Data structures are fundamental in R programming as they organize and store the data that one works with for analyses, visualizations, and other computational tasks. Understanding these structures is critical for effective manipulation of data and implementing various algorithms (Wickham & Grolemund, 2017). Below are the primary data structures that R provides.

#### Vectors {.unnumbered}

Vectors are one-dimensional arrays used to hold elements of a single data type. This could be numeric, character, or logical data types. Vectors are often used for operations that require the application of a function to each element in the data set (Maindonald & Braun, 2010).

Vectors can be created using the `c()` function, which combines elements into a vector.

*Creating a numeric vector*

```{r}
numeric_vector <- c(1, 2, 3, 4, 5)
```

*Creating a character vector*

```{r}
character_vector <- c("apple", "banana", "cherry")
```

*Creating a logical vector*

```{r}
logical_vector <- c(TRUE, FALSE, TRUE)
```

You can perform various operations on vectors like addition, subtraction, or applying a function to each element.

```{r}
# Adding two vectors
sum_vector <- numeric_vector + c(1, 1, 1, 1, 1)

# Calculating mean of a numeric vector
mean_value <- mean(numeric_vector)
```

#### Data Frames {.unnumbered}

Data frames serve as the fundamental data structure for data analysis in R. They are similar to matrices but allow different types of variables in different columns, which makes them extremely versatile (Chambers, 2008).

Data frames can be created using the `data.frame()` function.

```{r}
# Creating a data frame
df <- data.frame(Name = c("Alice", "Bob"), Age = c(23, 45), Gender = c("F", "M"))
```

Various operations like subsetting, merging, and sorting can be performed on data frames.

```{r}
# Subsetting data frame by column
subset_df <- df[, c("Name", "Age")]
```

#### Lists {.unnumbered}

Lists are an ordered collection of objects, which can be of different types and structures, including vectors, matrices, and even other lists (Wickham & Grolemund, 2017).

Lists can be created using the `list()` function.

```{r}
# Creating a list
my_list <- list(Name = "Alice", Age = 23, Scores = c(90, 85, 88))
```

Lists can be modified by adding, deleting, or updating list elements.

```{r}
# Updating a list element
my_list$Name <- "Bob"

# Adding a new list element
my_list$Email <- "bob@email.com"
```

By understanding these primary data structures, students in Mass Communications can gain a strong foundation for more complex data analyses relevant to their field, whether it involves analyzing large sets of textual data, audience metrics, or other forms of media data.

### Importing Data from a File {.unnumbered}

When working with larger datasets, such as CSV files, importing data into R is more efficient. A CSV (Comma Separated Values) file stores tabular data as plain text, making it easy to exchange data between programs. Below are several ways to import the **gaming-anxiety.csv** dataset into R.

#### Use `read.csv` from Base R {.unnumbered}

The `read.csv()` function is part of base R and can be used to import CSV files directly into your environment:

```{r}
# Reading the IMDb_Economist_tv_ratings dataset using read.csv from base R
csv_base <- read.csv("https://github.com/SIM-Lab-SIUE/SIM-Lab-SIUE.github.io/raw/refs/heads/main/research-methods/data/gaming-anxiety.csv", header = TRUE, stringsAsFactors = FALSE)
```

This code imports the dataset from the URL provided. The `header = TRUE` argument indicates that the first row contains variable names, and `stringsAsFactors = FALSE` prevents character strings from being converted to factors.

Use `write.csv()` to write a data frame to a csv.

#### Use `read_csv` from the `readr` Package {.unnumbered}

The `readr` package provides an alternative function, `read_csv()`, which offers better performance and flexibility:

```{r}
# Install the readr package if it's not already installed
# install.packages("readr")

# Load the readr package
library(readr)

# Reading the IMDb_Economist_tv_ratings dataset using read_csv from readr
csv_readr <- read_csv("https://github.com/SIM-Lab-SIUE/SIM-Lab-SIUE.github.io/raw/refs/heads/main/research-methods/data/gaming-anxiety.csv")
```

The `read_csv()` function is faster than `read.csv()` and automatically detects data types, making it easier to handle larger datasets efficiently.

Use `write_csv()` to write a data frame to a csv.

#### Use `fread` from the `data.table` Package {.unnumbered}

For very large datasets, `fread()` from the `data.table` package is a faster alternative:

```{r}
# Install the data.table package if it's not already installed
# install.packages("data.table")

# Load the data.table package
library(data.table)

# Reading the IMDb_Economist_tv_ratings dataset using fread from data.table
csv_datatable <- fread("https://github.com/SIM-Lab-SIUE/SIM-Lab-SIUE.github.io/raw/refs/heads/main/research-methods/data/gaming-anxiety.csv")
```

The `fread()` function provides high-speed reading for large CSV files, making it ideal for processing extensive datasets.

Use `fwrite()` to write a data frame to a csv.

#### Use `vroom,` from the `vroom` Package {.unnumbered}

The fastest method for reading rectangular data that I know of is `vroom()` from the `vroom` package:

```{r}
# Install the data.table package if it's not already installed
# install.packages("vroom")

# Load the data.table package
library(vroom)

# Reading the IMDb_Economist_tv_ratings dataset using fread from data.table
csv_vroom <- vroom("https://github.com/SIM-Lab-SIUE/SIM-Lab-SIUE.github.io/raw/refs/heads/main/research-methods/data/gaming-anxiety.csv")
```

The `vroom()` function provides the fastest current read for .csv files.

Use `vroom_write()` to write a data frame to a csv.

## Manipulating Data

Data manipulation is a crucial aspect of preparing datasets for analysis. In RStudio, the **`dplyr`** package---part of the tidyverse ecosystem---provides powerful, intuitive functions for transforming, summarizing, and reshaping data. This section introduces `dplyr` and demonstrates how to manipulate data using examples from the **billboard** dataset, which contains information about songs, performers, and chart positions.

### The `dplyr` Package {.unnumbered}

#### Introducing Tidyverse {.unnumbered}

**Tidyverse** is a collection of R packages designed for data science, which share an underlying design philosophy and programming style. The `dplyr` package is part of the tidyverse and is widely used for data manipulation tasks such as filtering rows, selecting columns, grouping data, and summarizing statistics.

To get started, load the tidyverse (or specifically `dplyr`) into your R environment:

```{r}
# Load the dplyr package
library(dplyr)
```

Load the **gaming_anxiety** dataset from an online file

```{r}
# Load the data.table package
library("data.table")

#@ Load the gaming_anxiety dataset
gaming_anxiety <- fread("https://github.com/SIM-Lab-SIUE/SIM-Lab-SIUE.github.io/raw/refs/heads/main/research-methods/data/gaming-anxiety.csv")
```

#### The Pipe Operator `%>%` {.unnumbered}

The pipe operator `%>%` passes the result of one function into the next. This allows you to build operations in readable, sequential steps.

Instead of:

```{r}
summarize(group_by(gaming_anxiety, Gender), avg_age = mean(Age, na.rm = TRUE))
```

Use:

```{r}
gaming_anxiety %>%
  group_by(Gender) %>%
  summarize(avg_age = mean(Age, na.rm = TRUE))
```

#### Important `dplyr` Commands {.unnumbered}

**01. `summarize()**

Calculates summary statistics across the entire dataset or within groups.

```{r}
gaming_anxiety %>%
  summarize(avg_hours = mean(Hours, na.rm = TRUE))
```

**02. `count()**

Counts the frequency of unique values in a column.

```{r}
gaming_anxiety %>%
  count(Platform)
```

**03. `group_by()**

Groups data by one or more variables, typically followed by `summarize()` or `mutate()`.

```{r}
gaming_anxiety %>%
  group_by(Gender) %>%
  summarize(mean_age = mean(Age, na.rm = TRUE))
```

**04. `ungroup()**

Removes grouping structure after a grouped operation.

```{r}
gaming_anxiety %>%
  group_by(Gender) %>%
  summarize(mean_age = mean(Age, na.rm = TRUE)) %>%
  ungroup()
```

**05. `mutate()**

Creates new variables or modifies existing ones.

```{r}
gaming_anxiety %>%
  mutate(hours_per_day = Hours / 7)
```

**06. `rowwise()**

Applies operations across columns within individual rows.

```{r}
gaming_anxiety %>%
  rowwise() %>%
  mutate(GAD_score = mean(c_across(GAD1:GAD7), na.rm = TRUE))
```

**07. `filter()**

Selects rows based on logical conditions.

```{r}
gaming_anxiety %>%
  filter(Hours > 20)
```

**08. `distinct()**

Returns unique rows based on selected columns.

```{r}
gaming_anxiety %>%
  distinct(Game)
```

**09. `slice()**

Selects rows by position index.

```{r}
gaming_anxiety %>%
  slice(1:5)
```

**10. `slice_sample()**

Randomly selects a number of rows.

```{r}
gaming_anxiety %>%
  slice_sample(n = 5)
```

**11. `slice_min()` and \`slice_max()**

Selects rows with the minimum or maximum value in a column.

```{r}
gaming_anxiety %>%
  slice_min(Age)

gaming_anxiety %>%
  slice_max(Hours)
```

**12. `arrange()**

Sorts the data by column values in ascending order.

```{r}
gaming_anxiety %>%
  arrange(Age)
```

**13. `desc()**

Used inside `arrange()` to sort values in descending order.

```{r}
gaming_anxiety %>%
  arrange(desc(Hours))
```

**14. `pull()**

Extracts a single column as a vector.

```{r}
gaming_anxiety %>%
  pull(Platform)
```

**15. `select()**

Selects specific columns from a dataset.

```{r}
gaming_anxiety %>%
  select(Gender, Age, Platform)
```

**16. `relocate()**

Changes the order of columns in the dataset.

```{r}
gaming_anxiety %>%
  relocate(Hours, .before = Gender)
```

**17. `across()**

Applies a function to multiple columns simultaneously.

```{r}
gaming_anxiety %>%
  mutate(across(GAD1:GAD7, ~ .x * 2))
```

**18. `c_across()**

Used inside `rowwise()` to perform operations across selected columns in each row.

```{r}
gaming_anxiety %>%
  rowwise() %>%
  mutate(SPIN_sum = sum(c_across(SPIN1:SPIN17), na.rm = TRUE))
```

**19. `rename()**

Renames one or more columns.

```{r}
gaming_anxiety %>%
  rename(Gender_Identity = Gender)
```

**20. `n()**

Returns the count of rows in each group, often used inside `summarize()`.

```{r}
gaming_anxiety %>%
  group_by(Platform) %>%
  summarize(count = n())
```

**21. `mean()`, `median()`, `sum()`, \`sd()**

Common summary functions used inside `summarize()` or `mutate()`.

```{r}
gaming_anxiety %>%
  summarize(mean_hours = mean(Hours, na.rm = TRUE),
            sd_hours = sd(Hours, na.rm = TRUE))
```


## Cleaning the Data to Include Only Valid Survey Responses

The full dataset contains **14250 response IDs**, but only **13464 are real, valid survey responses**. Some rows were added to simulate incomplete or fake data to teach cleaning and filtering. These steps will help you remove the simulated responses and retain only the clean, complete data needed for analysis.


### Step 01: Identify the Structure of the Data {.unnumbered}

Before filtering, examine how the dataset is organized. You should look at:
- Missing values
- Incomplete rows
- Common patterns in legitimate responses

```{r}
library(dplyr)

# Look at the dimensions of the full dataset
nrow(gaming_anxiety)
```

This should return 14250. But we only want 13464.

### Step 02: Filter Out Incomplete Responses {.unnumbered}

Now, remove simulated responses. We’ll assume that valid responses have:
- A non-missing value for **GAD1**, **SWL1**, and **SPIN1**
- A listed **Game** and **Age**

This combination ensures we're only keeping actual, completed surveys.

```{r}
valid_gaming_data <- gaming_anxiety %>%
  filter(
    if_all(GAD1:GAD7, ~ !is.na(.x)),
    if_all(SWL1:SWL5, ~ !is.na(.x)),
    !is.na(SPIN1),
    !is.na(Game),
    !is.na(Age)
  )
```

### Step 03: Check Your Work {.unnumbered}

After filtering, check that the dataset now contains exactly 13464 responses.

```{r}
nrow(valid_gaming_data)
```

You now have a clean version of the dataset that includes only complete and authentic responses. This version—**`valid_gaming_data`**—is the one you'll use in the next chapters on descriptive statistics, inferential tests, and data visualization.
